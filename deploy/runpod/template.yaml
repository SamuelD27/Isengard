# Isengard RunPod Pod Template
#
# Complete GPU pod with SSH, ComfyUI, API, and Worker.
#
# Features:
# - SSH access on port 22
# - Automatic model downloads (FLUX.1-dev, FLUX.1-schnell)
# - ComfyUI on port 8188
# - Isengard API on port 8000
# - Redis for job queue
# - Persistent storage on network volume
#
# Prerequisites:
# 1. Build and push the Docker image:
#    docker build -t ghcr.io/samueld27/isengard-runpod:latest -f deploy/runpod/Dockerfile .
#    docker push ghcr.io/samueld27/isengard-runpod:latest
#
# 2. Create a RunPod network volume (100GB+ recommended)
#
# 3. Set environment variables in RunPod template

name: isengard-gpu
description: "Isengard - Identity LoRA Training + Image Generation"

# Docker image
image: ghcr.io/samueld27/isengard-runpod:latest

# GPU Configuration
gpu:
  # Recommended: RTX 4090 (24GB) or A100 (40GB/80GB)
  # Minimum: RTX 3090 (24GB)
  type: RTX_4090
  count: 1

# Volume mount for persistent storage
volume:
  # Create at: https://www.runpod.io/console/user/storage
  size: 100  # GB
  mountPath: /runpod-volume

# Exposed ports
ports:
  - port: 22
    protocol: tcp
    name: ssh
  - port: 8000
    protocol: http
    name: api
  - port: 8188
    protocol: http
    name: comfyui

# Environment variables
env:
  # Required: HuggingFace token for FLUX model access
  - name: HF_TOKEN
    value: "${HF_TOKEN}"
    secret: true

  # Isengard configuration
  - name: ISENGARD_MODE
    value: "production"

  - name: VOLUME_ROOT
    value: "/runpod-volume/isengard"

  - name: LOG_DIR
    value: "/runpod-volume/isengard/logs"

  - name: LOG_LEVEL
    value: "INFO"

  # Redis (local on pod)
  - name: REDIS_URL
    value: "redis://localhost:6379"

  # ComfyUI (local on pod)
  - name: COMFYUI_URL
    value: "http://localhost:8188"

  - name: USE_REDIS
    value: "true"

  # Worker name (for multi-worker setups)
  - name: WORKER_NAME
    value: "runpod-worker-1"

  # Optional: SSH public key for key-based auth
  # If not set, a random password will be generated on startup
  # - name: PUBLIC_KEY
  #   value: "ssh-rsa AAAA..."

# Resource limits
resources:
  cpu: 8
  memory: 32Gi

# Health check
healthCheck:
  enabled: true
  path: /health
  port: 8000
  initialDelaySeconds: 120  # Models take time to download
  periodSeconds: 30

---
# Quick Start Guide
#
# 1. Deploy the template on RunPod
#
# 2. Wait for startup (check logs for "Startup Complete")
#    - First run downloads ~25GB of models
#    - Subsequent runs use cached models
#
# 3. Access services:
#    - SSH: ssh root@<pod-ip> (password shown in logs)
#    - API: http://<pod-ip>:8000/health
#    - ComfyUI: http://<pod-ip>:8188
#
# 4. Test the API:
#    curl http://<pod-ip>:8000/info
#    curl http://<pod-ip>:8000/api/characters
#
# 5. Check service status:
#    ssh root@<pod-ip>
#    # Inside pod:
#    redis-cli ping
#    curl localhost:8000/health
#    curl localhost:8188/system_stats
#    ps aux | grep python
#
# 6. View logs:
#    tail -f /runpod-volume/isengard/logs/api/startup.log
#    tail -f /runpod-volume/isengard/logs/worker/startup.log
#
# Troubleshooting:
# - Models not downloading: Check HF_TOKEN is set correctly
# - Services not starting: Check /runpod-volume/isengard/logs/
# - GPU not detected: Run nvidia-smi to verify
